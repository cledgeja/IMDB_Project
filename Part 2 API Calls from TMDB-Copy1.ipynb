{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d674590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json, math, time\n",
    "import glob\n",
    "import regex as re\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89cbdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyPath = %env CODINGDOJO\n",
    "with open(KeyPath) as f: \n",
    "    login = json.load(f)\n",
    "# other environment variables\n",
    "data_file = 'tmdb_results_combined.csv.gz'\n",
    "data_dir = 'data/'\n",
    "data_dump = 'data_dumps/'\n",
    "data_basics = 'title_basics.csv.gz'\n",
    "years_requested = [*range(2022,2023,1)]\n",
    "tmdb.API_KEY = login['tmdb-api-key-v3']\n",
    "# if all years ran do not retrive any results, no need to recompile final merged csv\n",
    "zero_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32ef0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    try:\n",
    "        movie = tmdb.Movies(movie_id)\n",
    "        movie_info = movie.info()\n",
    "        releases = movie.releases()\n",
    "        x=0\n",
    "        for c in releases['countries']:\n",
    "            if c['iso_3166_1'] == 'US' and len(c['certification'])>0:\n",
    "                x+=1\n",
    "                movie_info['certification'] = c['certification']\n",
    "        if x == 0:\n",
    "            movie_info['certification']=np.NaN            \n",
    "    except:\n",
    "        movie_info = {\"imdb_id\": movie_id}\n",
    "    return movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f23be57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7459471eff604b6da3311bba8632f034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d8e97c84c649708313e280659cc1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2022:   0%|          | 0/2545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for YEAR in tqdm_notebook(years_requested,desc='YEARS',position=0):\n",
    "    JSON_FILE = f'{data_dir}tmdb_api_results_{YEAR}.json'\n",
    "    #Create dump directory for each Year\n",
    "    if not os.path.exists(f'{data_dump}{YEAR}'):\n",
    "        os.makedirs(f'{data_dump}{YEAR}')\n",
    "    file_list =  [x.replace('.json','') for x in os.listdir(f'{data_dump}{YEAR}')]\n",
    "    #get complete list of movie_ids from the basics file for corresponding year \n",
    "    movie_ids = pd.read_csv(data_dir+data_basics)[['tconst','startYear']]\n",
    "    movie_ids = [*movie_ids['tconst'].loc[movie_ids['startYear']==YEAR]]\n",
    "\n",
    "    # filter out any ids that are already in file_data\n",
    "    #possible if there are interuptions when extracting data from API\n",
    "    movie_ids_to_get = [x for x in movie_ids if x not in file_list]\n",
    "    \n",
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        #print(movie_id)\n",
    "        json_req = get_movie_with_rating(movie_id)  #This uses your pre-made function\n",
    "        # Just rewrite entire file. could run again later to update/add results.\n",
    "        dump_file = f'{data_dump}{YEAR}/{movie_id}.json'\n",
    "        with open(dump_file,'w') as file:\n",
    "            #file_data.append(json_req)\n",
    "            json.dump(json_req,file)\n",
    "        # Short 150 ms sleep to prevent overwhelming server\n",
    "        time.sleep(0.15)\n",
    "\n",
    "    \n",
    "    file_list =  glob.glob(f'{data_dump}{YEAR}/*.json') # files = glob.glob('/YOUR/PATH/*')\n",
    "    json_data = list()\n",
    "    for x in file_list:\n",
    "        with open(x,'r') as file:\n",
    "            json_data.append(json.load(file))\n",
    "    with open(JSON_FILE, 'w') as output_file:\n",
    "        json.dump(json_data, output_file)\n",
    "\n",
    "    final_year_df = pd.read_json(json.dumps(json_data))\n",
    "    final_year_df.to_csv(f\"{data_dir}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "    #remove all the individual dumped data no longer needed once in final .json file\n",
    "    for x in file_list:\n",
    "        os.remove(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12ab580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#will always recreate the entire final data file because csv files really cannot be upserted\n",
    "# and appending can add duplicated rows\n",
    "\n",
    "#get a list of all csv.gz individual year files \n",
    "#https://stackoverflow.com/questions/2225564/get-a-filtered-list-of-files-in-a-directory\n",
    "\n",
    "files = [f for f in os.listdir(data_dir) if re.match(r'final_tmdb_data_.*\\.csv.gz', f)]\n",
    "\n",
    "#Save a final merged .csv.gz of all of the tmdb api data\n",
    "#write mode w+ will create file if not exists. a will append to end\n",
    "if zero_data == False:\n",
    "    cnt = 1\n",
    "    for x in files:\n",
    "        df= pd.read_csv(data_dir+x)\n",
    "        if cnt == 1:\n",
    "            df.to_csv(data_dir+data_file,mode='w+' ,compression=\"gzip\", index=False)\n",
    "            cnt+=1\n",
    "        elif cnt > 1:\n",
    "            df.to_csv(data_dir+data_file,mode='a' ,compression=\"gzip\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8cf4c",
   "metadata": {},
   "source": [
    "#### Other transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32f0d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#outside of loop for json to individual csv and combined\n",
    "file_list =  glob.glob(f'{data_dir}*.json')\n",
    "final_df = pd.DataFrame()\n",
    "for x in file_list:\n",
    "    with open(x,'r') as file:\n",
    "        YEAR = re.sub(r'[^0-9]','',x)\n",
    "        df = pd.read_json(json.dumps(json.load(file)))\n",
    "        df.to_csv(f\"{data_dir}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "        final_df = pd.concat([final_df,df],axis=0)\n",
    "final_df.to_csv(data_dir+data_file,mode='w+' ,compression=\"gzip\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363d82d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.duplicated(subset=['imdb_id','budget','revenue','certification']).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff99ec4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df.drop_duplicates(subset=['imdb_id','budget','revenue'],keep = 'last').reset_index(drop = True)\n",
    "final_df.duplicated(subset=['imdb_id','budget','revenue','certification']).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b077c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(data_dir+data_file,mode='w+' ,compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31d94b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R                                  6547\n",
       "NR                                 3476\n",
       "PG-13                              3417\n",
       "                                   1835\n",
       "PG                                 1517\n",
       "G                                   461\n",
       "NC-17                               161\n",
       "Unrated                               5\n",
       "-                                     1\n",
       "UR                                    1\n",
       "Not Rated                             1\n",
       "ScreamFest Horror Film Festival       1\n",
       "10                                    1\n",
       "Name: certification, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['certification'].str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057cef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix certification col\n",
    "repl_cert = {'UR':'NR',\n",
    "             'Not Rated':'NR',\n",
    "             'Unrated':'NR',\n",
    "             '-':'NR',\n",
    "             '10':np.nan,\n",
    "             'ScreamFest Horror Film Festival':'NR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bda7c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>certification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [adult, backdrop_path, belongs_to_collection, budget, genres, homepage, id, imdb_id, original_language, original_title, overview, popularity, poster_path, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, video, vote_average, vote_count, certification]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['certification'].str.contains('one',case=False)==True ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4163b9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69254 entries, 0 to 69253\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  62057 non-null  float64\n",
      " 1   backdrop_path          38650 non-null  object \n",
      " 2   belongs_to_collection  3922 non-null   object \n",
      " 3   budget                 62057 non-null  float64\n",
      " 4   genres                 62057 non-null  object \n",
      " 5   homepage               59585 non-null  object \n",
      " 6   id                     62057 non-null  float64\n",
      " 7   imdb_id                69254 non-null  object \n",
      " 8   original_language      62057 non-null  object \n",
      " 9   original_title         62057 non-null  object \n",
      " 10  overview               62057 non-null  object \n",
      " 11  popularity             62057 non-null  float64\n",
      " 12  poster_path            56302 non-null  object \n",
      " 13  production_companies   62057 non-null  object \n",
      " 14  production_countries   62057 non-null  object \n",
      " 15  release_date           62057 non-null  object \n",
      " 16  revenue                62057 non-null  float64\n",
      " 17  runtime                61431 non-null  float64\n",
      " 18  spoken_languages       62057 non-null  object \n",
      " 19  status                 62057 non-null  object \n",
      " 20  tagline                62057 non-null  object \n",
      " 21  title                  62057 non-null  object \n",
      " 22  video                  62057 non-null  float64\n",
      " 23  vote_average           62057 non-null  float64\n",
      " 24  vote_count             62057 non-null  float64\n",
      " 25  certification          17424 non-null  object \n",
      "dtypes: float64(9), object(17)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b36337ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\tmdb_api_results_2000-orginal.json\n",
      "data\\tmdb_api_results_2000.json\n",
      "data\\tmdb_api_results_2001.json\n",
      "data\\tmdb_api_results_2002.json\n",
      "data\\tmdb_api_results_2003.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'certification'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-0b97acf14c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmovie\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'certification'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'imdb_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'imdb_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'certification'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_movie_with_rating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'certification'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"records\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'certification'"
     ]
    }
   ],
   "source": [
    "#update ratings in json files\n",
    "for x in glob.glob(f'{data_dir}/tmdb_api_results_*.json'):\n",
    "    df = pd.read_json(x)\n",
    "    try:\n",
    "        for movie in [df[df['certification'] == '']['imdb_id']][0] :\n",
    "            df.loc[df['imdb_id']==movie,'certification'] = get_movie_with_rating(movie)['certification']\n",
    "            time.sleep(0.15)\n",
    "    except:\n",
    "        print(movie,':cert error')\n",
    "        pass\n",
    "    with open(x,'w') as output_file:\n",
    "        json.dump(json.loads(df.to_json(orient=\"records\")),output_file)\n",
    "        print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
